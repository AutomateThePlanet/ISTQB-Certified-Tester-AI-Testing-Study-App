window.glossary = [
  {
    "term": "Artificial Intelligence (AI)",
    "definition": "The ability of a system to acquire, process, and apply knowledge to perform tasks that usually require human intelligence.",
    "example": "AI can include image recognition, decision-making, or speech processing."
  },
  {
    "term": "AI Effect",
    "definition": "The tendency for AI achievements to be discounted as \"not real AI\" once they become commonplace.",
    "example": "People no longer consider email spam filtering as AI, even though it is."
  },
  {
    "term": "Narrow AI (Weak AI)",
    "definition": "AI designed to perform a specific task or a narrow range of tasks without general reasoning.",
    "example": "A recommendation engine that only suggests movies based on user preferences."
  },
  {
    "term": "General AI",
    "definition": "A theoretical AI with the ability to perform any intellectual task a human can do.",
    "example": "A robot that can plan, learn, and reason across domains like a human."
  },
  {
    "term": "Super AI",
    "definition": "A hypothetical AI that surpasses human intelligence across all areas.",
    "example": "An AI that improves its own design without human input and becomes exponentially smarter."
  },
  {
    "term": "Conventional (Rule-Based) System",
    "definition": "A system that uses fixed rules or logic explicitly programmed by humans.",
    "example": "An \"if-else\" rules engine used to determine loan eligibility."
  },
  {
    "term": "AI-Based System",
    "definition": "A system that includes AI components such as ML models or reasoning engines to make data-driven decisions.",
    "example": "A fraud detection system using neural networks."
  },
  {
    "term": "AI Technology",
    "definition": "The computational approaches enabling AI capabilities, including ML, NLP, robotics, etc.",
    "example": "A support bot using NLP to understand user queries."
  },
  {
    "term": "AI Development Framework",
    "definition": "A software toolkit or platform for building and deploying AI models.",
    "example": "TensorFlow, PyTorch, or scikit-learn."
  },
  {
    "term": "Hardware for AI-Based Systems",
    "definition": "Specialized processors and accelerators optimized for AI tasks such as model training and inference.",
    "example": "GPUs, TPUs, or neuromorphic chips."
  },
  {
    "term": "AI as a Service (AIaaS)",
    "definition": "Cloud-based AI functionalities provided as services, such as image recognition or language translation.",
    "example": "Google Cloud Vision API for image analysis."
  },
  {
    "term": "AIaaS Contract",
    "definition": "A service-level agreement that defines metrics (e.g., accuracy), uptime, and responsibilities for AI services.",
    "example": "A 99.9% uptime guarantee with a commitment to retrain the model periodically."
  },
  {
    "term": "Pre-Trained Model",
    "definition": "An existing AI model trained on large datasets and reused or adapted for new tasks.",
    "example": "Using BERT for a custom text classification task."
  },
  {
    "term": "Transfer Learning",
    "definition": "A technique where knowledge from a pre-trained model is adapted to a new, but related, task.",
    "example": "Fine-tuning an image classifier trained on ImageNet for recognizing plant species."
  },
  {
    "term": "Risk of Using Pre-Trained Models",
    "definition": "The potential drawbacks of using pre-trained models, such as inherited bias or lack of fit to new data.",
    "example": "A sentiment model pre-trained on product reviews may misclassify healthcare content."
  },
  {
    "term": "AI Standards and Regulations",
    "definition": "Legal and normative frameworks guiding the safe and ethical development of AI systems.",
    "example": "The EU AI Act or ISO/IEC 22989."
  },
  {
    "term": "Flexibility",
    "definition": "The ease with which an AI system can be modified for use in new contexts or environments.",
    "example": "A chatbot retrained for use in a different language domain."
  },
  {
    "term": "Adaptability",
    "definition": "The ability of an AI system to adjust to changes in its environment or requirements.",
    "example": "A self-driving car adapting to different road conditions."
  },
  {
    "term": "Autonomy",
    "definition": "The extent to which an AI system can operate independently without human intervention.",
    "example": "A robot vacuum navigating and cleaning on its own."
  },
  {
    "term": "Evolution",
    "definition": "The capability of an AI system to evolve its behavior over time, either by self-learning or being updated.",
    "example": "A recommender system that updates its suggestions based on user feedback."
  },
  {
    "term": "Bias",
    "definition": "A systematic error in AI outcomes due to flawed data, algorithms, or assumptions.",
    "example": "An AI that rates resumes unfairly based on gender indicators."
  },
  {
    "term": "Ethics",
    "definition": "The application of moral principles in AI development and testing to ensure fair and responsible use.",
    "example": "Avoiding the use of AI in surveillance without public consent."
  },
  {
    "term": "Side Effects",
    "definition": "Unintended and potentially harmful consequences of an AI system's behavior.",
    "example": "A chatbot generating toxic responses when not properly constrained."
  },
  {
    "term": "Reward Hacking",
    "definition": "When an AI exploits loopholes in the reward function to achieve high scores in unintended ways.",
    "example": "A cleaning robot hiding dirt to appear successful in cleaning."
  },
  {
    "term": "Transparency",
    "definition": "The openness with which an AI system's operations and decision-making can be inspected.",
    "example": "Displaying the reasoning path of a diagnostic system."
  },
  {
    "term": "Interpretability",
    "definition": "The degree to which a human can understand how an AI model arrives at its outputs.",
    "example": "A decision tree's logic can be traced from root to leaf."
  },
  {
    "term": "Explainability",
    "definition": "The ability to explain the internal mechanics or predictions of an AI system in a user-understandable way.",
    "example": "Using LIME to explain why a loan was denied."
  },
  {
    "term": "Safety",
    "definition": "The assurance that an AI system does not cause harm to humans or the environment.",
    "example": "Ensuring a self-driving car avoids collisions under edge conditions."
  },
  {
    "term": "Supervised Learning",
    "definition": "A machine learning approach where models are trained on labeled data with known inputs and outputs.",
    "example": "Classifying spam vs. non-spam emails using historical labels."
  },
  {
    "term": "Unsupervised Learning",
    "definition": "A learning method where the model identifies patterns in data without labeled outputs.",
    "example": "Clustering customers based on purchasing behavior."
  },
  {
    "term": "Reinforcement Learning",
    "definition": "A learning paradigm where an agent interacts with an environment and learns by receiving rewards or penalties.",
    "example": "Training an AI to play chess by rewarding wins."
  },
  {
    "term": "ML Workflow",
    "definition": "A sequence of steps in machine learning, including data preparation, training, validation, testing, deployment, and monitoring.",
    "example": "Starting with raw data, creating features, training a model, and validating accuracy."
  },
  {
    "term": "Algorithm Selection",
    "definition": "The process of choosing the most suitable ML algorithm based on task type, data characteristics, and performance goals.",
    "example": "Selecting a random forest over logistic regression for better non-linear classification."
  },
  {
    "term": "Overfitting",
    "definition": "When a model learns training data too well, including noise, and performs poorly on unseen data.",
    "example": "A classifier with near-perfect training accuracy but low test accuracy."
  },
  {
    "term": "Underfitting",
    "definition": "When a model fails to capture the underlying patterns of the data and performs poorly on both training and test sets.",
    "example": "A linear model applied to a highly non-linear dataset."
  },
  {
    "term": "Data Preparation",
    "definition": "The process of cleaning, transforming, and organizing raw data into a usable format for ML models.",
    "example": "Normalizing numeric values and handling missing entries before training."
  },
  {
    "term": "Training Dataset",
    "definition": "A labeled dataset used to fit the parameters of an ML model during the learning process.",
    "example": "Thousands of tagged images used to train a vision model."
  },
  {
    "term": "Validation Dataset",
    "definition": "A dataset used to tune model hyperparameters and prevent overfitting during training.",
    "example": "Adjusting the learning rate based on validation accuracy."
  },
  {
    "term": "Test Dataset",
    "definition": "A separate dataset used to evaluate the final model's generalization performance.",
    "example": "Assessing how well a trained classifier performs on never-seen-before images."
  },
  {
    "term": "Dataset Quality Issues",
    "definition": "Problems in data such as noise, outliers, or mislabels that negatively affect ML model accuracy.",
    "example": "Incorrectly tagged samples leading to biased predictions."
  },
  {
    "term": "Data Labeling",
    "definition": "Assigning meaningful labels to raw data to enable supervised learning.",
    "example": "Marking product reviews as positive or negative."
  },
  {
    "term": "Mislabeled Data",
    "definition": "Incorrect labels in a dataset that can lead to faulty model training.",
    "example": "A positive review labeled as negative corrupting sentiment analysis results."
  },
  {
    "term": "Data Augmentation",
    "definition": "Techniques to artificially increase the diversity of the training set by modifying existing data.",
    "example": "Rotating or flipping images to simulate different perspectives."
  },
  {
    "term": "Data Quality",
    "definition": "The degree to which data is complete, accurate, relevant, and free from noise.",
    "example": "Removing duplicate and irrelevant entries from a training set."
  },
  {
    "term": "Data Annotation Approaches",
    "definition": "Manual, semi-automatic, or crowdsourced methods for labeling data.",
    "example": "Using Amazon Mechanical Turk to tag images."
  },
  {
    "term": "Confusion Matrix",
    "definition": "A table showing the counts of true positives, true negatives, false positives, and false negatives in a classification model.",
    "example": "Used to calculate precision, recall, and F1-score."
  },
  {
    "term": "Precision",
    "definition": "The proportion of true positives among all predicted positives.",
    "example": "Of all emails classified as spam, how many actually are spam."
  },
  {
    "term": "Recall (Sensitivity)",
    "definition": "The proportion of true positives among all actual positives.",
    "example": "Of all actual spam emails, how many the model correctly identified."
  },
  {
    "term": "F1-Score",
    "definition": "The harmonic mean of precision and recall, used to balance both in one metric.",
    "example": "Used when both false positives and false negatives matter."
  },
  {
    "term": "Accuracy",
    "definition": "The ratio of correct predictions (both positives and negatives) to total predictions.",
    "example": "Correct predictions out of all email classifications."
  },
  {
    "term": "ROC Curve",
    "definition": "A graph showing the trade-off between true positive rate and false positive rate at different thresholds.",
    "example": "Evaluating the performance of binary classifiers."
  },
  {
    "term": "AUC (Area Under the Curve)",
    "definition": "A scalar value representing the area under the ROC curve; closer to 1 indicates better performance.",
    "example": "AUC of 0.95 indicates strong separability of classes."
  },
  {
    "term": "R-Squared (R²)",
    "definition": "A metric for regression models indicating how well predictions approximate actual values.",
    "example": "R² = 0.92 means 92% of variance is explained by the model."
  },
  {
    "term": "Mean Squared Error (MSE)",
    "definition": "The average of the squared differences between predicted and actual values in regression.",
    "example": "Penalizes large errors more than small ones."
  },
  {
    "term": "Benchmark Suite",
    "definition": "A standardized dataset and metric package used to compare ML models.",
    "example": "ImageNet used to evaluate image classifiers."
  },
  {
    "term": "Performance Metric Selection",
    "definition": "Choosing the appropriate metric depending on task, imbalance, and business needs.",
    "example": "Using recall over accuracy in medical diagnosis."
  },
  {
    "term": "Metric Limitations",
    "definition": "The inability of metrics to fully capture real-world effectiveness or ethical implications.",
    "example": "High accuracy may hide performance gaps on minority subgroups."
  },
  {
    "term": "Neural Network",
    "definition": "A type of machine learning model inspired by the structure of the human brain, composed of layers of interconnected nodes (neurons).",
    "example": "A neural network used to recognize handwritten digits."
  },
  {
    "term": "Perceptron",
    "definition": "The simplest type of neural network consisting of a single neuron with adjustable weights.",
    "example": "Used for binary classification of linearly separable data."
  },
  {
    "term": "Activation Function",
    "definition": "A function applied to each neuron's output to introduce non-linearity into the network.",
    "example": "ReLU (Rectified Linear Unit), Sigmoid."
  },
  {
    "term": "Feedforward Neural Network",
    "definition": "A neural network in which connections between nodes do not form cycles; data flows in one direction.",
    "example": "Used in image classification tasks."
  },
  {
    "term": "Deep Neural Network (DNN)",
    "definition": "A neural network with multiple hidden layers between input and output, capable of learning complex features.",
    "example": "Used in speech recognition systems."
  },
  {
    "term": "Coverage Measures (NN Testing)",
    "definition": "Metrics used to evaluate how well neural network components (e.g., neurons, paths) are exercised by test inputs.",
    "example": "Neuron coverage tracks which internal nodes are activated by inputs."
  },
  {
    "term": "Testing Neural Networks",
    "definition": "Techniques used to verify and validate neural networks through various test data, coverage analysis, and robustness checks.",
    "example": "Input perturbation tests to check for adversarial vulnerability."
  },
  {
    "term": "Specification of AI-Based Systems",
    "definition": "The process of defining requirements and constraints for systems that include AI components.",
    "example": "Documenting how a fraud detection model should behave under various transaction types."
  },
  {
    "term": "Input Data Testing",
    "definition": "Verifying the validity, consistency, and robustness of data inputs used by AI systems.",
    "example": "Ensuring all images fed to a classifier are in the expected format and resolution."
  },
  {
    "term": "ML Model Testing",
    "definition": "Testing the AI model as an isolated unit to assess accuracy, robustness, and sensitivity to input variations.",
    "example": "Running test cases to check for adversarial weaknesses."
  },
  {
    "term": "Component Testing (AI Context)",
    "definition": "Testing individual components of an AI-based system, including both AI and non-AI parts.",
    "example": "Validating the data preprocessing module independently of the model."
  },
  {
    "term": "Component Integration Testing",
    "definition": "Verifying the interactions between AI components and other software modules.",
    "example": "Testing how a chatbot engine integrates with a user interface."
  },
  {
    "term": "System Testing (AI Context)",
    "definition": "End-to-end testing of the entire AI-based system in a realistic environment.",
    "example": "Testing a self-driving module with simulated traffic and sensor input."
  },
  {
    "term": "Acceptance Testing (AI Context)",
    "definition": "Confirming that the AI system meets user and business requirements under realistic conditions.",
    "example": "Validating that a recommendation engine meets the specified user engagement KPIs."
  },
  {
    "term": "Test Data for AI",
    "definition": "Curated data used during different test levels to evaluate the AI system's behavior and quality.",
    "example": "Scenario-specific test data for rare edge cases in facial recognition."
  },
  {
    "term": "Automation Bias",
    "definition": "The tendency of humans to over-trust decisions made by automated systems, including AI.",
    "example": "Operators blindly accepting a medical diagnosis from an AI tool without verification."
  },
  {
    "term": "Documenting an AI Component",
    "definition": "The act of recording the model's purpose, data, version, behavior, and known limitations.",
    "example": "A factsheet for a vision model noting its accuracy, training data, and known biases."
  },
  {
    "term": "Testing for Concept Drift",
    "definition": "Verifying whether the AI system's accuracy degrades over time due to changes in input data distribution.",
    "example": "A sentiment classifier trained before a major political shift becoming obsolete."
  },
  {
    "term": "Test Approach Selection for ML",
    "definition": "Choosing appropriate test techniques (e.g., black-box, metamorphic, BTB) based on the characteristics of the ML system.",
    "example": "Using metamorphic testing to validate a model when no oracle is available."
  },
  {
    "term": "Self-Learning System",
    "definition": "An AI system that can modify its behavior over time based on feedback or environmental changes without explicit reprogramming.",
    "example": "A recommendation engine that updates suggestions based on user interactions."
  },
  {
    "term": "Testing Self-Learning Systems",
    "definition": "Validating that self-updating models maintain quality, do not regress, and align with expected outcomes.",
    "example": "Running regression tests after every model retraining cycle."
  },
  {
    "term": "Autonomous AI-Based System",
    "definition": "A system that operates with minimal or no human intervention across varying conditions.",
    "example": "A delivery drone adjusting its route in real time."
  },
  {
    "term": "Algorithmic Bias",
    "definition": "Bias introduced by the learning algorithm's structure or design.",
    "example": "A classifier favoring certain features because of how the algorithm weighs inputs."
  },
  {
    "term": "Sample Bias",
    "definition": "Bias arising from unrepresentative or skewed training data.",
    "example": "A face recognition system trained only on light-skinned faces."
  },
  {
    "term": "Inappropriate Bias",
    "definition": "Any form of bias that results in unfair, unethical, or unintended outcomes.",
    "example": "An AI system that scores applicants differently based on zip code."
  },
  {
    "term": "Probabilistic AI System",
    "definition": "An AI system that uses probabilistic reasoning, often producing different outputs for the same input.",
    "example": "A chatbot generating varied responses to the same question."
  },
  {
    "term": "Non-Deterministic Behavior",
    "definition": "The property of an AI system to yield different outputs even when given identical inputs, due to randomness or learned variability.",
    "example": "A model using dropout layers during inference."
  },
  {
    "term": "Explainability Testing",
    "definition": "Validating that the system can provide understandable reasons for its outputs or actions.",
    "example": "Using LIME or SHAP to assess feature importance for predictions."
  },
  {
    "term": "Interpretability Testing",
    "definition": "Evaluating whether a human can follow and understand the logic behind model outputs.",
    "example": "Checking if decision paths in a model are human-comprehensible."
  },
  {
    "term": "Transparency Testing",
    "definition": "Assessing how openly the system communicates its internal workings and decision basis.",
    "example": "Verifying that a black-box model exposes key influencing factors."
  },
  {
    "term": "Test Oracle for AI",
    "definition": "A mechanism or reference used to determine expected outcomes in testing AI systems, often difficult to define.",
    "example": "Using a prior model version or a rule-based baseline as a pseudo-oracle."
  },
  {
    "term": "Test Objectives and Acceptance Criteria (AI Context)",
    "definition": "The specific goals and quality thresholds defined to evaluate whether an AI system meets business and ethical requirements.",
    "example": "The system must detect fraudulent transactions with at least 90% recall and no evidence of demographic bias."
  },
  {
    "term": "Adversarial Attack",
    "definition": "A deliberate manipulation of input data to deceive an AI model into making incorrect predictions.",
    "example": "Slightly altering a stop sign image so that it is misclassified as a speed limit sign."
  },
  {
    "term": "Data Poisoning",
    "definition": "The injection of malicious data into the training set to corrupt the learned model.",
    "example": "Planting biased or mislabeled samples to skew model behavior."
  },
  {
    "term": "Pairwise Testing",
    "definition": "A combinatorial test technique where inputs are selected such that all possible pairs of input values are covered at least once.",
    "example": "Reducing the number of test cases for a self-driving car by testing every combination of two features like weather and road type."
  },
  {
    "term": "Back-to-Back Testing (BTB)",
    "definition": "Comparing the output of a new AI system with a reference system (oracle or previous version) to identify inconsistencies.",
    "example": "Comparing outputs of a new chatbot engine against a prior stable version."
  },
  {
    "term": "A/B Testing",
    "definition": "A method of testing two variants (A and B) to determine which performs better based on a defined metric.",
    "example": "Comparing conversion rates between two ML-generated website layouts."
  },
  {
    "term": "Metamorphic Testing (MT)",
    "definition": "A technique that validates expected relationships between multiple inputs and outputs, especially when no oracle is available.",
    "example": "Changing the brightness of an image and expecting the classifier output to remain consistent."
  },
  {
    "term": "Exploratory Testing of AI",
    "definition": "A manual and unscripted testing approach aimed at discovering unexpected behaviors or weaknesses in AI systems.",
    "example": "A tester interacting freely with a chatbot to expose edge cases."
  },
  {
    "term": "Exploratory Data Analysis (EDA)",
    "definition": "A process of analyzing datasets to summarize their main characteristics, often visually.",
    "example": "Plotting distributions to detect outliers or data skew."
  },
  {
    "term": "Experience-Based Testing",
    "definition": "Leveraging the tester's domain knowledge and intuition to uncover faults in AI systems.",
    "example": "An experienced tester crafting input scenarios based on known model weaknesses."
  },
  {
    "term": "Test Technique Selection (AI Context)",
    "definition": "Choosing appropriate testing methods (e.g., MT, BTB, A/B) based on model properties, system complexity, and test objectives.",
    "example": "Using metamorphic testing when deterministic outputs are unavailable."
  },
  {
    "term": "Test Environment (AI Context)",
    "definition": "A controlled setup that enables the execution of tests on AI-based systems under repeatable and observable conditions.",
    "example": "A sandbox with simulated sensor data for testing autonomous vehicle models."
  },
  {
    "term": "Virtual Test Environment",
    "definition": "A simulated or emulated environment used to test AI behavior without interacting with the real world.",
    "example": "A virtual warehouse to test robot navigation without physical hardware."
  },
  {
    "term": "Environment Simulation",
    "definition": "The reproduction of real-world operating conditions in a test setting to observe AI behavior.",
    "example": "Simulating weather, traffic, and lighting conditions for testing a self-driving AI."
  },
  {
    "term": "Test Environment Requirements",
    "definition": "The necessary tools, infrastructure, data, and monitoring components required to validate AI systems effectively.",
    "example": "GPU clusters, synthetic data generators, and logging systems for neural network testing."
  },
  {
    "term": "Test Environment Challenges (AI)",
    "definition": "Difficulties in replicating real-world variability, dynamic data, and stochastic model behavior in a controlled test setting.",
    "example": "Reproducing a rare edge case in live customer chat data."
  },
  {
    "term": "AI for Testing",
    "definition": "The application of AI techniques to automate, optimize, and improve the software testing process.",
    "example": "Using an AI tool to identify redundant test cases or prioritize tests."
  },
  {
    "term": "AI Technologies for Testing",
    "definition": "The specific AI techniques such as machine learning, NLP, and computer vision used to support testing activities.",
    "example": "Using NLP to analyze and classify bug reports."
  },
  {
    "term": "AI for Defect Prediction",
    "definition": "The use of ML models to predict where defects are most likely to occur based on historical data.",
    "example": "Predicting defect-prone modules from commit history and code metrics."
  },
  {
    "term": "AI for Test Case Generation",
    "definition": "Generating test inputs, sequences, or scripts automatically using AI models trained on existing test artifacts.",
    "example": "A system learning from past test scripts to generate new ones for similar functionality."
  },
  {
    "term": "AI for Regression Optimization",
    "definition": "Using AI to reduce, reorder, or prioritize regression test suites for faster feedback and risk-based coverage.",
    "example": "Running only the most relevant tests after a code change."
  },
  {
    "term": "AI for Defect Analysis",
    "definition": "Analyzing past defects using AI to find patterns, root causes, or to cluster related bugs.",
    "example": "Grouping similar bug reports using unsupervised learning."
  },
  {
    "term": "AI for GUI Testing",
    "definition": "Applying AI (e.g., visual recognition or reinforcement learning) to test graphical user interfaces.",
    "example": "An AI agent interacting with a dynamic web UI to detect layout or functionality issues."
  },
  {
    "term": "Testing Through the GUI (AI-Supported)",
    "definition": "Executing functional or usability tests via the user interface, assisted by AI to navigate and evaluate elements.",
    "example": "A vision-based AI identifying and interacting with buttons even after UI changes."
  },
  {
    "term": "AI in Test Report Analysis",
    "definition": "Using AI to summarize, classify, and extract insights from large sets of test execution logs or failure messages.",
    "example": "A bot highlighting the root cause across multiple failed test runs."
  },
  {
    "term": "Testability Challenge (AI Context)",
    "definition": "A difficulty in verifying system requirements due to vagueness, adaptivity, or probabilistic behavior in AI models.",
    "example": "\"Achieve 90% accuracy\" is harder to validate than fixed threshold outputs."
  },
  {
    "term": "Model Testing Stage",
    "definition": "The evaluation phase where trained AI models are validated against unseen data, and bias is least likely to originate.",
    "example": "Bias is more often introduced during data collection or training, not testing."
  },
  {
    "term": "Inaccurate ML Algorithm",
    "definition": "An ML model or training setup that generalizes poorly due to algorithmic inefficiencies, leading to unintended outcomes.",
    "example": "An agent exploiting reward loopholes due to poor generalization."
  },
  {
    "term": "Cluster Discovery (Unsupervised Learning)",
    "definition": "The task of grouping unlabeled data into meaningful clusters based on similarity.",
    "example": "Segmenting users into behavior-based groups for marketing."
  },
  {
    "term": "Post-hoc Explainability",
    "definition": "Techniques applied after model training to interpret or explain black-box models.",
    "example": "Using SHAP values to explain feature impact in a neural network."
  },
  {
    "term": "Fairness Metric",
    "definition": "A quantitative method to evaluate bias or discrimination in model predictions across demographic or group attributes.",
    "example": "Comparing false positive rates between different age groups."
  },
  {
    "term": "Human Trust in AI",
    "definition": "The confidence users place in AI systems, influenced by transparency, explainability, and consistent behavior.",
    "example": "A medical AI showing rationale for diagnosis increases trust among physicians."
  }
];